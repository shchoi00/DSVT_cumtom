2025-05-26 16:37:41,899   INFO  Database filter by min points Truck: 2193 => 1722
2025-05-26 16:37:41,899   INFO  Database filter by min points Forklift: 671 => 478
2025-05-26 16:37:41,900   INFO  Database filter by min points Worker: 794 => 415
2025-05-26 16:37:41,901   INFO  Loading Custom dataset.
2025-05-26 16:37:41,903   INFO  Total samples for CUSTOM dataset: 430
2025-05-26 16:37:42,642   INFO  DistributedDataParallel(
  (module): CenterPoint(
    (vfe): DynamicPillarVFE(
      (pfn_layers): ModuleList(
        (0): PFNLayerV2(
          (linear): Linear(in_features=10, out_features=64, bias=False)
          (norm): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): PFNLayerV2(
          (linear): Linear(in_features=128, out_features=128, bias=False)
          (norm): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (backbone_3d): DSVT(
      (input_layer): DSVTInputLayer(
        (posembed_layers): ModuleList(
          (0): ModuleList(
            (0-3): 4 x ModuleList(
              (0-1): 2 x PositionEmbeddingLearned(
                (position_embedding_head): Sequential(
                  (0): Linear(in_features=2, out_features=128, bias=True)
                  (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                  (3): Linear(in_features=128, out_features=128, bias=True)
                )
              )
            )
          )
        )
      )
      (stage_0): ModuleList(
        (0-3): 4 x DSVTBlock(
          (encoder_list): ModuleList(
            (0-1): 2 x DSVT_EncoderLayer(
              (win_attn): SetAttention(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
                )
                (linear1): Linear(in_features=128, out_features=256, bias=True)
                (dropout): Dropout(p=0, inplace=False)
                (linear2): Linear(in_features=256, out_features=128, bias=True)
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (dropout1): Identity()
                (dropout2): Identity()
              )
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (residual_norm_stage_0): ModuleList(
        (0-3): 4 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (map_to_bev_module): PointPillarScatter3d()
    (pfe): None
    (backbone_2d): BaseBEVResBackbone(
      (blocks): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
            (downsample_layer): Sequential(
              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
            (downsample_layer): Sequential(
              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
            (downsample_layer): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu1): ReLU()
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): SyncBatchNorm(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
            (relu2): ReLU()
          )
        )
      )
      (deblocks): ModuleList(
        (0): Sequential(
          (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): Sequential(
          (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (2): Sequential(
          (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
    )
    (dense_head): CenterHead(
      (shared_conv): Sequential(
        (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (heads_list): ModuleList(
        (0): SeparateHead(
          (center): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (center_z): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (dim): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (rot): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (iou): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (hm): Sequential(
            (0): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU()
            )
            (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (hm_loss_func): FocalLossCenterNet()
      (reg_loss_func): RegLossCenterNet()
    )
    (point_head): None
    (roi_head): None
  )
)
2025-05-26 16:37:42,655   INFO  **********************Start training dsvt_plain_1f_onestage_SL**********************
epochs:   0%|                                                                                                                                                                                                                                                                                                          | 0/1000 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)                                      | 0/11 [00:00<?, ?it/s]
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/shchoi/workspace/DSVT/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:103: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, ``)
/home/shchoi/workspace/DSVT/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
2025-05-26 16:40:23,740   INFO  epoch: 0/1000, acc_iter=11, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 02:41/2:25:09, loss_hm=5.8956, loss_loc=9.5309, loss=19.1886719790372, d_time=0.03(0.05), f_time=0.48(0.74), b_time=0.52(0.79), norm=58.543365478515625, lr=5.0005735153812656e-05
epochs:   0%|▎                                                                                                                                                                                                                                                                                             | 1/1000 [02:43<45:19:40, 163.34s/it]2025-05-26 16:41:48,786   INFO  epoch: 1/1000, acc_iter=22, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 04:06/1:58:13, loss_hm=4.8748, loss_loc=8.3814, loss=16.58349288593639, d_time=0.03(0.06), f_time=0.47(0.57), b_time=0.50(0.64), norm=45.60879898071289, lr=5.0025291661919425e-05
epochs:   0%|▌                                                                                                                                                                                                                                                                                             | 2/1000 [04:08<32:30:13, 117.25s/it]2025-05-26 16:43:13,648   INFO  epoch: 2/1000, acc_iter=33, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 05:30/1:55:27, loss_hm=3.9819, loss_loc=8.2208, loss=15.396845297379928, d_time=0.03(0.06), f_time=0.46(0.56), b_time=0.50(0.62), norm=36.77883529663086, lr=5.005872566976182e-05
epochs:   0%|▊                                                                                                                                                                                                                                                                                             | 3/1000 [05:33<28:22:06, 102.43s/it]2025-05-26 16:44:36,075   INFO  epoch: 3/1000, acc_iter=44, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 06:53/1:51:48, loss_hm=3.4392, loss_loc=7.9501, loss=14.564900224859064, d_time=0.03(0.06), f_time=0.47(0.75), b_time=0.50(0.80), norm=31.586957931518555, lr=5.0106035114973007e-05
epochs:   0%|█▏                                                                                                                                                                                                                                                                                             | 4/1000 [06:55<26:07:22, 94.42s/it]2025-05-26 16:46:01,291   INFO  epoch: 4/1000, acc_iter=55, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 08:18/1:58:31, loss_hm=3.1043, loss_loc=7.8738, loss=14.094036535783248, d_time=0.03(0.05), f_time=0.45(0.67), b_time=0.48(0.72), norm=28.651765823364258, lr=5.016721707928347e-05
epochs:   0%|█▍                                                                                                                                                                                                                                                                                             | 5/1000 [08:20<25:10:37, 91.09s/it]2025-05-26 16:47:24,756   INFO  epoch: 5/1000, acc_iter=66, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 09:42/2:07:56, loss_hm=2.8190, loss_loc=7.9165, loss=13.883859287608754, d_time=0.03(0.06), f_time=0.46(0.69), b_time=0.49(0.74), norm=22.394277572631836, lr=5.0242267788701354e-05
epochs:   1%|█▋                                                                                                                                                                                                                                                                                             | 6/1000 [09:43<24:26:21, 88.51s/it]2025-05-26 16:48:48,854   INFO  epoch: 6/1000, acc_iter=77, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 11:06/1:50:29, loss_hm=2.7401, loss_loc=7.7818, loss=13.580782456831498, d_time=0.04(0.05), f_time=0.45(0.64), b_time=0.49(0.69), norm=20.162200927734375, lr=5.03311826137455e-05
epochs:   1%|██                                                                                                                                                                                                                                                                                             | 7/1000 [11:08<24:01:07, 87.08s/it]2025-05-26 16:50:13,098   INFO  epoch: 7/1000, acc_iter=88, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 12:30/1:51:07, loss_hm=2.5798, loss_loc=7.6476, loss=13.26738253506747, d_time=0.03(0.05), f_time=0.44(0.64), b_time=0.47(0.70), norm=21.740615844726562, lr=5.043395606973077e-05
epochs:   1%|██▎                                                                                                                                                                                                                                                                                            | 8/1000 [12:32<23:44:37, 86.17s/it]2025-05-26 16:51:37,481   INFO  epoch: 8/1000, acc_iter=99, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 13:54/1:51:46, loss_hm=2.4486, loss_loc=7.6491, loss=13.242907610806553, d_time=0.03(0.06), f_time=0.46(0.64), b_time=0.49(0.70), norm=23.55966567993164, lr=5.055058181710606e-05
epochs:   1%|██▌                                                                                                                                                                                                                                                                                            | 9/1000 [13:56<23:33:49, 85.60s/it]2025-05-26 16:53:02,446   INFO  epoch: 9/1000, acc_iter=110, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 15:19/1:52:48, loss_hm=2.3435, loss_loc=7.6489, loss=13.142167871648615, d_time=0.04(0.06), f_time=0.45(0.63), b_time=0.49(0.70), norm=22.248315811157227, lr=5.068105266184609e-05
epochs:   1%|██▊                                                                                                                                                                                                                                                                                           | 10/1000 [15:21<23:29:08, 85.40s/it]2025-05-26 16:54:27,206   INFO  epoch: 10/1000, acc_iter=121, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 16:44/1:51:19, loss_hm=2.4261, loss_loc=7.5992, loss=13.045402526855469, d_time=0.03(0.05), f_time=0.46(0.63), b_time=0.49(0.69), norm=18.700084686279297, lr=5.0825360555894496e-05
epochs:   1%|███▏                                                                                                                                                                                                                                                                                          | 11/1000 [16:46<23:25:09, 85.25s/it]2025-05-26 16:55:50,648   INFO  epoch: 11/1000, acc_iter=132, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 18:07/1:51:31, loss_hm=2.4047, loss_loc=7.6314, loss=13.043545809659092, d_time=0.03(0.06), f_time=0.47(0.70), b_time=0.50(0.76), norm=23.285579681396484, lr=5.098349659766061e-05
epochs:   1%|███▍                                                                                                                                                                                                                                                                                          | 12/1000 [18:09<23:14:02, 84.66s/it]2025-05-26 16:57:14,273   INFO  epoch: 12/1000, acc_iter=143, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 19:31/2:03:25, loss_hm=2.3351, loss_loc=7.5155, loss=12.855615615844727, d_time=0.04(0.06), f_time=0.44(0.63), b_time=0.48(0.69), norm=21.460617065429688, lr=5.11554510325686e-05
epochs:   1%|███▋                                                                                                                                                                                                                                                                                          | 13/1000 [19:33<23:07:33, 84.35s/it]2025-05-26 16:58:37,814   INFO  epoch: 13/1000, acc_iter=154, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 20:55/2:19:45, loss_hm=2.3179, loss_loc=7.6164, loss=12.919115500016646, d_time=0.04(0.06), f_time=0.46(0.75), b_time=0.50(0.81), norm=16.6380672454834, lr=5.134121325365881e-05
epochs:   1%|████                                                                                                                                                                                                                                                                                          | 14/1000 [20:57<23:02:11, 84.11s/it]2025-05-26 17:00:01,062   INFO  epoch: 14/1000, acc_iter=165, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 22:18/1:50:42, loss_hm=2.3458, loss_loc=7.4401, loss=12.900449839505283, d_time=0.04(0.06), f_time=0.46(0.69), b_time=0.51(0.75), norm=17.524076461791992, lr=5.154077180224249e-05
epochs:   2%|████▎                                                                                                                                                                                                                                                                                         | 15/1000 [22:20<22:56:06, 83.82s/it]2025-05-26 17:01:26,563   INFO  epoch: 15/1000, acc_iter=176, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 23:43/1:49:39, loss_hm=2.4431, loss_loc=7.4756, loss=12.818349491466176, d_time=0.04(0.06), f_time=0.46(0.68), b_time=0.49(0.74), norm=18.26576805114746, lr=5.175411436860838e-05
epochs:   2%|████▌                                                                                                                                                                                                                                                                                         | 16/1000 [23:45<23:03:24, 84.35s/it]2025-05-26 17:02:49,915   INFO  epoch: 16/1000, acc_iter=187, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 25:07/1:51:04, loss_hm=2.3900, loss_loc=7.4954, loss=12.860626307400791, d_time=0.03(0.05), f_time=0.45(0.72), b_time=0.48(0.77), norm=19.916738510131836, lr=5.198122779278202e-05
epochs:   2%|████▊                                                                                                                                                                                                                                                                                         | 17/1000 [25:09<22:57:05, 84.05s/it]2025-05-26 17:04:13,024   INFO  epoch: 17/1000, acc_iter=198, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:10/00:00, time_cost(all): 26:30/2:43:42, loss_hm=2.4362, loss_loc=7.5654, loss=12.914159254594283, d_time=0.04(0.06), f_time=0.46(0.72), b_time=0.50(0.78), norm=16.911724090576172, lr=5.222209806533758e-05
epochs:   2%|█████▏                                                                                                                                                                                                                                                                                        | 18/1000 [26:32<22:50:46, 83.75s/it]2025-05-26 17:05:38,641   INFO  epoch: 18/1000, acc_iter=209, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 27:55/1:49:10, loss_hm=2.2466, loss_loc=7.4402, loss=12.789777755737305, d_time=0.04(0.06), f_time=0.47(0.65), b_time=0.50(0.71), norm=19.201356887817383, lr=5.2476710328262116e-05
epochs:   2%|█████▍                                                                                                                                                                                                                                                                                        | 19/1000 [27:57<22:58:47, 84.33s/it]2025-05-26 17:06:53,306   INFO  epoch: 19/1000, acc_iter=220, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 29:10/1:49:49, loss_hm=2.4244, loss_loc=7.5139, loss=12.814207770607688, d_time=0.04(0.06), f_time=0.46(0.61), b_time=0.50(0.66), norm=17.486595153808594, lr=5.2745048875871866e-05
epochs:   2%|█████▋                                                                                                                                                                                                                                                                                        | 20/1000 [29:12<22:10:38, 81.47s/it]2025-05-26 17:08:18,544   INFO  epoch: 20/1000, acc_iter=231, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 30:35/1:52:32, loss_hm=2.3219, loss_loc=7.5849, loss=12.971672578291459, d_time=0.04(0.05), f_time=0.46(0.66), b_time=0.50(0.71), norm=15.236181259155273, lr=5.302709715578128e-05
epochs:   2%|██████                                                                                                                                                                                                                                                                                        | 21/1000 [30:37<22:27:35, 82.59s/it]2025-05-26 17:09:42,546   INFO  epoch: 21/1000, acc_iter=242, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:09/00:00, time_cost(all): 31:59/2:27:59, loss_hm=2.2843, loss_loc=7.4516, loss=12.811768185008656, d_time=0.04(0.06), f_time=0.44(0.67), b_time=0.48(0.73), norm=15.27184772491455, lr=5.3322837769923816e-05
epochs:   2%|██████▎                                                                                                                                                                                                                                                                                       | 22/1000 [32:01<22:32:36, 82.98s/it]2025-05-26 17:11:07,367   INFO  epoch: 22/1000, acc_iter=253, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 33:24/1:52:47, loss_hm=2.3036, loss_loc=7.5189, loss=12.838531060652299, d_time=0.03(0.06), f_time=0.46(0.64), b_time=0.50(0.70), norm=17.07274055480957, lr=5.363225247562544e-05
epochs:   2%|██████▌                                                                                                                                                                                                                                                                                       | 23/1000 [33:26<22:41:03, 83.59s/it]2025-05-26 17:12:33,377   INFO  epoch: 23/1000, acc_iter=264, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 34:50/1:49:10, loss_hm=2.3888, loss_loc=7.4587, loss=12.795750617980957, d_time=0.04(0.06), f_time=0.45(0.67), b_time=0.48(0.74), norm=18.390199661254883, lr=5.395532218672956e-05
epochs:   2%|██████▊                                                                                                                                                                                                                                                                                       | 24/1000 [34:52<22:50:38, 84.26s/it]2025-05-26 17:13:58,341   INFO  epoch: 24/1000, acc_iter=275, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 36:15/1:59:54, loss_hm=2.3301, loss_loc=7.5658, loss=12.918576760725541, d_time=0.04(0.06), f_time=0.45(0.69), b_time=0.49(0.74), norm=16.579105377197266, lr=5.4292026974774466e-05
epochs:   2%|███████▏                                                                                                                                                                                                                                                                                      | 25/1000 [36:17<22:52:31, 84.46s/it]2025-05-26 17:15:20,948   INFO  epoch: 25/1000, acc_iter=286, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 37:38/1:48:29, loss_hm=2.2966, loss_loc=7.6183, loss=12.94691189852628, d_time=0.04(0.06), f_time=0.46(0.75), b_time=0.50(0.81), norm=17.781679153442383, lr=5.464234607022308e-05
epochs:   3%|███████▍                                                                                                                                                                                                                                                                                      | 26/1000 [37:40<22:42:08, 83.91s/it]2025-05-26 17:16:44,757   INFO  epoch: 26/1000, acc_iter=297, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 39:02/1:49:29, loss_hm=2.4003, loss_loc=7.4364, loss=12.804889418862082, d_time=0.04(0.06), f_time=0.45(0.67), b_time=0.49(0.73), norm=15.802422523498535, lr=5.500625786374324e-05
epochs:   3%|███████▋                                                                                                                                                                                                                                                                                      | 27/1000 [39:03<22:40:06, 83.87s/it]2025-05-26 17:18:09,488   INFO  epoch: 27/1000, acc_iter=308, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 40:26/1:56:49, loss_hm=2.1235, loss_loc=7.4643, loss=12.799852804704146, d_time=0.04(0.06), f_time=0.46(0.66), b_time=0.50(0.72), norm=15.095669746398926, lr=5.5383739907541427e-05
epochs:   3%|████████                                                                                                                                                                                                                                                                                      | 28/1000 [40:28<22:43:08, 84.14s/it]2025-05-26 17:19:32,577   INFO  epoch: 28/1000, acc_iter=319, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 41:49/1:48:35, loss_hm=2.3050, loss_loc=7.5195, loss=12.807364723899148, d_time=0.03(0.06), f_time=0.46(0.71), b_time=0.49(0.77), norm=16.119064331054688, lr=5.5774768916747085e-05
epochs:   3%|████████▎                                                                                                                                                                                                                                                                                     | 29/1000 [41:51<22:36:37, 83.83s/it]2025-05-26 17:20:58,266   INFO  epoch: 29/1000, acc_iter=330, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 43:15/1:56:20, loss_hm=2.3174, loss_loc=7.6119, loss=13.026459867304022, d_time=0.03(0.06), f_time=0.46(0.67), b_time=0.49(0.73), norm=14.547574996948242, lr=5.6179320770849016e-05
epochs:   3%|████████▌                                                                                                                                                                                                                                                                                     | 30/1000 [43:17<22:44:06, 84.38s/it]2025-05-26 17:22:22,727   INFO  epoch: 30/1000, acc_iter=341, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 44:40/1:52:04, loss_hm=2.2973, loss_loc=7.5184, loss=12.872366298328746, d_time=0.04(0.05), f_time=0.45(0.65), b_time=0.49(0.71), norm=16.341373443603516, lr=5.659737051518323e-05
epochs:   3%|████████▊                                                                                                                                                                                                                                                                                     | 31/1000 [44:41<22:43:08, 84.41s/it]2025-05-26 17:23:46,853   INFO  epoch: 31/1000, acc_iter=352, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 46:04/2:17:03, loss_hm=2.3091, loss_loc=7.3922, loss=12.692112229087137, d_time=0.04(0.06), f_time=0.44(0.67), b_time=0.48(0.72), norm=16.161663055419922, lr=5.7028892362472256e-05
epochs:   3%|█████████▏                                                                                                                                                                                                                                                                                    | 32/1000 [46:06<22:40:50, 84.35s/it]2025-05-26 17:25:12,120   INFO  epoch: 32/1000, acc_iter=363, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 47:29/1:52:29, loss_hm=2.1763, loss_loc=7.4737, loss=12.785140817815607, d_time=0.04(0.06), f_time=0.45(0.66), b_time=0.50(0.72), norm=13.893845558166504, lr=5.747385969441597e-05
epochs:   3%|█████████▍                                                                                                                                                                                                                                                                                    | 33/1000 [47:31<22:43:30, 84.60s/it]2025-05-26 17:26:36,407   INFO  epoch: 33/1000, acc_iter=374, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 48:53/1:56:29, loss_hm=2.0945, loss_loc=7.4406, loss=12.674020593816584, d_time=0.03(0.06), f_time=0.46(0.71), b_time=0.48(0.77), norm=17.508136749267578, lr=5.7932245063333355e-05
epochs:   3%|█████████▋                                                                                                                                                                                                                                                                                    | 34/1000 [48:55<22:40:37, 84.51s/it]2025-05-26 17:28:00,342   INFO  epoch: 34/1000, acc_iter=385, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 50:17/1:47:18, loss_hm=2.2292, loss_loc=7.4392, loss=12.690483266657049, d_time=0.04(0.05), f_time=0.46(0.68), b_time=0.50(0.73), norm=13.92273998260498, lr=5.840402019385567e-05
epochs:   4%|██████████                                                                                                                                                                                                                                                                                    | 35/1000 [50:19<22:36:27, 84.34s/it]2025-05-26 17:29:24,468   INFO  epoch: 35/1000, acc_iter=396, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 51:41/1:47:36, loss_hm=2.2396, loss_loc=7.4654, loss=12.73243253881281, d_time=0.03(0.06), f_time=0.46(0.64), b_time=0.49(0.70), norm=14.819347381591797, lr=5.888915598467056e-05
epochs:   4%|██████████▎                                                                                                                                                                                                                                                                                   | 36/1000 [51:43<22:33:41, 84.25s/it]2025-05-26 17:30:48,276   INFO  epoch: 36/1000, acc_iter=407, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 53:05/1:48:21, loss_hm=2.0941, loss_loc=7.4676, loss=12.726046475497158, d_time=0.03(0.06), f_time=0.47(0.67), b_time=0.49(0.73), norm=15.049712181091309, lr=5.9387622510317266e-05
epochs:   4%|██████████▌                                                                                                                                                                                                                                                                                   | 37/1000 [53:07<22:30:19, 84.13s/it]2025-05-26 17:32:10,984   INFO  epoch: 37/1000, acc_iter=418, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:10/00:00, time_cost(all): 54:28/2:48:26, loss_hm=2.2200, loss_loc=7.3755, loss=12.651169083335184, d_time=0.04(0.06), f_time=0.46(0.73), b_time=0.50(0.79), norm=14.891433715820312, lr=5.989938902303257e-05
epochs:   4%|██████████▊                                                                                                                                                                                                                                                                                   | 38/1000 [54:30<22:22:06, 83.71s/it]2025-05-26 17:33:33,088   INFO  epoch: 38/1000, acc_iter=429, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 55:50/1:48:27, loss_hm=2.2903, loss_loc=7.3220, loss=12.656425215981223, d_time=0.04(0.06), f_time=0.45(0.73), b_time=0.49(0.79), norm=15.904193878173828, lr=6.042442395464727e-05
epochs:   4%|███████████▏                                                                                                                                                                                                                                                                                  | 39/1000 [55:52<22:12:54, 83.22s/it]2025-05-26 17:34:56,285   INFO  epoch: 39/1000, acc_iter=440, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 57:13/1:47:05, loss_hm=2.0999, loss_loc=7.4115, loss=12.671833038330078, d_time=0.03(0.05), f_time=0.46(0.73), b_time=0.49(0.78), norm=15.297088623046875, lr=6.0962694918533596e-05
epochs:   4%|███████████▍                                                                                                                                                                                                                                                                                  | 40/1000 [57:15<22:12:34, 83.29s/it]2025-05-26 17:36:15,965   INFO  epoch: 40/1000, acc_iter=451, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 58:33/1:46:20, loss_hm=2.2329, loss_loc=7.4968, loss=12.765705368735574, d_time=0.04(0.06), f_time=0.45(0.77), b_time=0.49(0.82), norm=14.990222930908203, lr=6.15141687116031e-05
epochs:   4%|███████████▋                                                                                                                                                                                                                                                                                  | 41/1000 [58:35<21:52:49, 82.14s/it]2025-05-26 17:37:37,763   INFO  epoch: 41/1000, acc_iter=462, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 59:55/1:46:44, loss_hm=2.3239, loss_loc=7.3630, loss=12.673679871992631, d_time=0.04(0.05), f_time=0.44(0.75), b_time=0.48(0.80), norm=16.7377872467041, lr=6.207881131635451e-05
epochs:   4%|████████████                                                                                                                                                                                                                                                                                  | 42/1000 [59:56<21:49:35, 82.02s/it]2025-05-26 17:39:00,315   INFO  epoch: 42/1000, acc_iter=473, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:01:17/1:47:23, loss_hm=2.2718, loss_loc=7.3706, loss=12.627216252413662, d_time=0.04(0.06), f_time=0.45(0.75), b_time=0.49(0.81), norm=14.739913940429688, lr=6.265658790297231e-05
epochs:   4%|████████████▏                                                                                                                                                                                                                                                                               | 43/1000 [1:01:19<21:51:10, 82.20s/it]2025-05-26 17:40:24,004   INFO  epoch: 43/1000, acc_iter=484, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:10/00:00, time_cost(all): 1:02:41/2:46:58, loss_hm=2.3250, loss_loc=7.4829, loss=12.825038649819113, d_time=0.04(0.05), f_time=0.47(0.74), b_time=0.50(0.80), norm=14.21879768371582, lr=6.324746283147502e-05
epochs:   4%|████████████▍                                                                                                                                                                                                                                                                               | 44/1000 [1:02:43<21:57:18, 82.68s/it]2025-05-26 17:41:49,490   INFO  epoch: 44/1000, acc_iter=495, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:04:06/1:46:53, loss_hm=2.4413, loss_loc=7.3793, loss=12.688075499101119, d_time=0.03(0.06), f_time=0.46(0.67), b_time=0.49(0.73), norm=13.28713607788086, lr=6.385139965391377e-05
epochs:   4%|████████████▊                                                                                                                                                                                                                                                                               | 45/1000 [1:04:08<22:08:43, 83.48s/it]2025-05-26 17:43:09,633   INFO  epoch: 45/1000, acc_iter=500, cur_iter=4/11, batch_size=10, time_cost(epoch): 00:04/00:06, time_cost(all): 1:05:26/2:50:51, loss_hm=2.4462, loss_loc=7.4105, loss=12.716828536987304, d_time=0.03(0.08), f_time=0.56(0.83), b_time=0.59(0.91), norm=13.219669342041016, lr=6.413022432638773e-05
2025-05-26 17:43:13,080   INFO  epoch: 45/1000, acc_iter=506, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 1:05:30/2:12:26, loss_hm=2.1726, loss_loc=7.3519, loss=12.608622074127197, d_time=0.04(0.06), f_time=0.45(0.67), b_time=0.49(0.73), norm=13.5960111618042, lr=6.446836111662064e-051 [00:00<?, ?it/s]
epochs:   5%|█████████████                                                                                                                                                                                                                                                                               | 46/1000 [1:05:32<22:07:44, 83.51s/it]2025-05-26 17:44:37,941   INFO  epoch: 46/1000, acc_iter=517, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:06:55/1:47:04, loss_hm=2.1484, loss_loc=7.3102, loss=12.576994115656072, d_time=0.04(0.06), f_time=0.45(0.64), b_time=0.50(0.70), norm=15.37602424621582, lr=6.509830916250634e-05
epochs:   5%|█████████████▎                                                                                                                                                                                                                                                                              | 47/1000 [1:06:57<22:13:06, 83.93s/it]2025-05-26 17:46:01,120   INFO  epoch: 47/1000, acc_iter=528, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:08:18/1:45:48, loss_hm=2.1452, loss_loc=7.4115, loss=12.677967071533203, d_time=0.04(0.06), f_time=0.45(0.69), b_time=0.48(0.75), norm=15.278627395629883, lr=6.574120493340815e-05
epochs:   5%|█████████████▋                                                                                                                                                                                                                                                                              | 48/1000 [1:08:20<22:07:48, 83.69s/it]2025-05-26 17:47:26,484   INFO  epoch: 48/1000, acc_iter=539, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:09:43/1:47:35, loss_hm=1.9805, loss_loc=7.4763, loss=12.662378918040883, d_time=0.04(0.05), f_time=0.46(0.64), b_time=0.51(0.70), norm=14.265473365783691, lr=6.639700877248669e-05
epochs:   5%|█████████████▉                                                                                                                                                                                                                                                                              | 49/1000 [1:09:45<22:14:36, 84.20s/it]2025-05-26 17:48:51,028   INFO  epoch: 49/1000, acc_iter=550, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 1:11:08/1:51:09, loss_hm=2.2294, loss_loc=7.3067, loss=12.559751944108443, d_time=0.04(0.06), f_time=0.45(0.63), b_time=0.49(0.69), norm=13.98090934753418, lr=6.70656802266718e-05
epochs:   5%|██████████████▏                                                                                                                                                                                                                                                                             | 50/1000 [1:11:10<22:14:46, 84.30s/it]2025-05-26 17:50:14,996   INFO  epoch: 50/1000, acc_iter=561, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 1:12:32/2:13:39, loss_hm=2.2263, loss_loc=7.4843, loss=12.694338885220615, d_time=0.04(0.06), f_time=0.46(0.75), b_time=0.50(0.81), norm=14.697135925292969, lr=6.774717804915875e-05
epochs:   5%|██████████████▍                                                                                                                                                                                                                                                                             | 51/1000 [1:12:34<22:12:01, 84.22s/it]2025-05-26 17:51:41,376   INFO  epoch: 51/1000, acc_iter=572, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 1:13:58/1:56:52, loss_hm=2.3012, loss_loc=7.3350, loss=12.623939947648482, d_time=0.04(0.06), f_time=0.45(0.68), b_time=0.49(0.74), norm=14.70389461517334, lr=6.84414602019515e-05
epochs:   5%|██████████████▊                                                                                                                                                                                                                                                                             | 52/1000 [1:14:00<22:20:40, 84.85s/it]2025-05-26 17:53:05,894   INFO  epoch: 52/1000, acc_iter=583, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:15:23/1:45:15, loss_hm=2.1278, loss_loc=7.2622, loss=12.559769717129795, d_time=0.03(0.06), f_time=0.45(0.75), b_time=0.48(0.81), norm=13.500420570373535, lr=6.914848385845666e-05
epochs:   5%|███████████████                                                                                                                                                                                                                                                                             | 53/1000 [1:15:25<22:17:38, 84.75s/it]2025-05-26 17:54:25,738   INFO  epoch: 53/1000, acc_iter=594, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:14/00:01, time_cost(all): 1:16:43/3:53:16, loss_hm=2.1374, loss_loc=7.2026, loss=12.481556979092685, d_time=0.04(0.06), f_time=0.46(0.87), b_time=0.49(0.93), norm=15.54072093963623, lr=6.986820540612462e-05
epochs:   5%|███████████████▎                                                                                                                                                                                                                                                                            | 54/1000 [1:16:44<21:53:18, 83.30s/it]2025-05-26 17:55:50,444   INFO  epoch: 54/1000, acc_iter=605, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:18:07/1:46:20, loss_hm=2.3263, loss_loc=7.3878, loss=12.678222742947666, d_time=0.04(0.05), f_time=0.45(0.69), b_time=0.49(0.75), norm=13.181690216064453, lr=7.060058044914018e-05
epochs:   6%|███████████████▌                                                                                                                                                                                                                                                                            | 55/1000 [1:18:09<21:58:26, 83.71s/it]2025-05-26 17:57:14,504   INFO  epoch: 55/1000, acc_iter=616, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 1:19:31/1:52:02, loss_hm=2.1575, loss_loc=7.4368, loss=12.681413910605691, d_time=0.03(0.05), f_time=0.46(0.69), b_time=0.49(0.75), norm=15.447197914123535, lr=7.134556381116085e-05
epochs:   6%|███████████████▉                                                                                                                                                                                                                                                                            | 56/1000 [1:19:33<21:58:26, 83.80s/it]2025-05-26 17:58:39,019   INFO  epoch: 56/1000, acc_iter=627, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:20:56/1:46:02, loss_hm=2.1552, loss_loc=7.2514, loss=12.489656101573598, d_time=0.03(0.06), f_time=0.46(0.65), b_time=0.49(0.71), norm=14.429883003234863, lr=7.210310953810375e-05
epochs:   6%|████████████████▏                                                                                                                                                                                                                                                                           | 57/1000 [1:20:58<22:00:31, 84.02s/it]2025-05-26 18:00:03,514   INFO  epoch: 57/1000, acc_iter=638, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:22:20/1:45:03, loss_hm=2.1198, loss_loc=7.3233, loss=12.505859375, d_time=0.03(0.06), f_time=0.45(0.63), b_time=0.49(0.68), norm=13.589497566223145, lr=7.287317090097994e-05
epochs:   6%|████████████████▍                                                                                                                                                                                                                                                                           | 58/1000 [1:22:22<22:01:13, 84.15s/it]2025-05-26 18:01:30,321   INFO  epoch: 58/1000, acc_iter=649, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 1:23:47/2:18:11, loss_hm=2.1352, loss_loc=7.2848, loss=12.51100037314675, d_time=0.03(0.05), f_time=0.45(0.77), b_time=0.49(0.82), norm=14.529879570007324, lr=7.365570039877733e-05
epochs:   6%|████████████████▊                                                                                                                                                                                                                                                                           | 59/1000 [1:23:49<22:12:28, 84.96s/it]2025-05-26 18:02:54,044   INFO  epoch: 59/1000, acc_iter=660, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:25:11/1:45:08, loss_hm=2.2014, loss_loc=7.4152, loss=12.695463960820978, d_time=0.03(0.06), f_time=0.45(0.69), b_time=0.48(0.74), norm=16.16395378112793, lr=7.445064976139052e-05
epochs:   6%|█████████████████                                                                                                                                                                                                                                                                           | 60/1000 [1:25:13<22:06:19, 84.66s/it]2025-05-26 18:04:18,281   INFO  epoch: 60/1000, acc_iter=671, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 1:26:35/1:52:58, loss_hm=2.0926, loss_loc=7.2585, loss=12.466652870178223, d_time=0.03(0.05), f_time=0.44(0.69), b_time=0.48(0.74), norm=15.406418800354004, lr=7.525796995259818e-05
epochs:   6%|█████████████████▎                                                                                                                                                                                                                                                                          | 61/1000 [1:26:37<22:01:57, 84.47s/it]2025-05-26 18:05:42,658   INFO  epoch: 61/1000, acc_iter=682, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:27:59/1:46:14, loss_hm=2.1651, loss_loc=7.2446, loss=12.485987489873713, d_time=0.03(0.06), f_time=0.46(0.63), b_time=0.49(0.69), norm=13.862483978271484, lr=7.607761117308813e-05
epochs:   6%|█████████████████▌                                                                                                                                                                                                                                                                          | 62/1000 [1:28:01<21:59:53, 84.43s/it]2025-05-26 18:07:04,660   INFO  epoch: 62/1000, acc_iter=693, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 1:29:22/2:07:07, loss_hm=2.1554, loss_loc=7.4505, loss=12.70548204942183, d_time=0.04(0.06), f_time=0.44(0.76), b_time=0.48(0.82), norm=13.383666038513184, lr=7.690952286352901e-05
epochs:   6%|█████████████████▉                                                                                                                                                                                                                                                                          | 63/1000 [1:29:23<21:47:14, 83.71s/it]2025-05-26 18:08:28,135   INFO  epoch: 63/1000, acc_iter=704, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:30:45/1:44:33, loss_hm=2.1676, loss_loc=7.3069, loss=12.57002067565918, d_time=0.03(0.06), f_time=0.46(0.68), b_time=0.49(0.74), norm=14.106521606445312, lr=7.775365370768918e-05
epochs:   6%|██████████████████▏                                                                                                                                                                                                                                                                         | 64/1000 [1:30:47<21:44:41, 83.63s/it]2025-05-26 18:09:53,187   INFO  epoch: 64/1000, acc_iter=715, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:32:10/1:43:08, loss_hm=2.0751, loss_loc=7.3450, loss=12.547500697049228, d_time=0.04(0.06), f_time=0.46(0.63), b_time=0.50(0.69), norm=13.703448295593262, lr=7.860995163560191e-05
epochs:   6%|██████████████████▍                                                                                                                                                                                                                                                                         | 65/1000 [1:32:12<21:50:06, 84.07s/it]2025-05-26 18:11:17,489   INFO  epoch: 65/1000, acc_iter=726, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:33:34/1:45:16, loss_hm=2.3347, loss_loc=7.1597, loss=12.433802084489303, d_time=0.04(0.05), f_time=0.46(0.72), b_time=0.50(0.77), norm=13.913954734802246, lr=7.947836382677742e-05
epochs:   7%|██████████████████▋                                                                                                                                                                                                                                                                         | 66/1000 [1:33:36<21:49:17, 84.11s/it]2025-05-26 18:12:42,457   INFO  epoch: 66/1000, acc_iter=737, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:34:59/1:42:52, loss_hm=2.1836, loss_loc=7.3336, loss=12.593793088739568, d_time=0.03(0.06), f_time=0.46(0.74), b_time=0.50(0.79), norm=13.615036964416504, lr=8.035883671346126e-05
epochs:   7%|███████████████████                                                                                                                                                                                                                                                                         | 67/1000 [1:35:01<21:52:20, 84.39s/it]2025-05-26 18:14:05,952   INFO  epoch: 67/1000, acc_iter=748, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 1:36:23/2:01:06, loss_hm=2.2107, loss_loc=7.2761, loss=12.516315026716752, d_time=0.04(0.06), f_time=0.45(0.66), b_time=0.49(0.72), norm=13.892227172851562, lr=8.125131598393841e-05
epochs:   7%|███████████████████▎                                                                                                                                                                                                                                                                        | 68/1000 [1:36:25<21:46:58, 84.14s/it]2025-05-26 18:15:31,526   INFO  epoch: 68/1000, acc_iter=759, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 1:37:48/1:50:15, loss_hm=2.1423, loss_loc=7.1666, loss=12.417694525285201, d_time=0.04(0.06), f_time=0.47(0.68), b_time=0.51(0.74), norm=13.212366104125977, lr=8.215574658588338e-05
epochs:   7%|███████████████████▌                                                                                                                                                                                                                                                                        | 69/1000 [1:37:50<21:51:48, 84.54s/it]2025-05-26 18:16:56,797   INFO  epoch: 69/1000, acc_iter=770, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:39:14/1:45:14, loss_hm=2.2793, loss_loc=7.2489, loss=12.45327446677468, d_time=0.04(0.05), f_time=0.45(0.65), b_time=0.50(0.70), norm=12.697208404541016, lr=8.307207272975652e-05
epochs:   7%|███████████████████▉                                                                                                                                                                                                                                                                        | 70/1000 [1:39:15<21:53:51, 84.76s/it]2025-05-26 18:18:21,189   INFO  epoch: 70/1000, acc_iter=781, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:40:38/1:40:51, loss_hm=2.2307, loss_loc=7.3211, loss=12.561644033952193, d_time=0.03(0.05), f_time=0.45(0.65), b_time=0.47(0.70), norm=15.209653854370117, lr=8.400023789224495e-05
epochs:   7%|████████████████████▏                                                                                                                                                                                                                                                                       | 71/1000 [1:40:40<21:50:46, 84.66s/it]2025-05-26 18:19:45,029   INFO  epoch: 71/1000, acc_iter=792, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:42:02/1:46:44, loss_hm=2.2327, loss_loc=7.3116, loss=12.569892883300781, d_time=0.03(0.06), f_time=0.45(0.63), b_time=0.48(0.69), norm=13.380532264709473, lr=8.494018481974939e-05
epochs:   7%|████████████████████▍                                                                                                                                                                                                                                                                       | 72/1000 [1:42:04<21:45:24, 84.40s/it]2025-05-26 18:21:05,735   INFO  epoch: 72/1000, acc_iter=803, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:43:23/1:42:43, loss_hm=2.1900, loss_loc=7.1391, loss=12.33567003770308, d_time=0.03(0.05), f_time=0.45(0.79), b_time=0.48(0.84), norm=13.791363716125488, lr=8.589185553191576e-05
epochs:   7%|████████████████████▋                                                                                                                                                                                                                                                                       | 73/1000 [1:43:24<21:26:52, 83.29s/it]2025-05-26 18:22:28,342   INFO  epoch: 73/1000, acc_iter=814, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:44:45/1:43:48, loss_hm=2.0645, loss_loc=7.1962, loss=12.383538072759455, d_time=0.04(0.06), f_time=0.46(0.71), b_time=0.51(0.77), norm=13.950643539428711, lr=8.685519132521185e-05
epochs:   7%|█████████████████████                                                                                                                                                                                                                                                                       | 74/1000 [1:44:47<21:22:29, 83.10s/it]2025-05-26 18:23:52,019   INFO  epoch: 74/1000, acc_iter=825, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:46:09/1:44:37, loss_hm=2.3684, loss_loc=7.3319, loss=12.600699251348322, d_time=0.03(0.06), f_time=0.45(0.65), b_time=0.49(0.71), norm=13.848047256469727, lr=8.783013277654822e-05
epochs:   8%|█████████████████████▎                                                                                                                                                                                                                                                                      | 75/1000 [1:46:11<21:23:32, 83.26s/it]2025-05-26 18:25:16,693   INFO  epoch: 75/1000, acc_iter=836, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:47:34/1:45:24, loss_hm=2.2872, loss_loc=7.1525, loss=12.396049672907049, d_time=0.04(0.06), f_time=0.47(0.67), b_time=0.51(0.73), norm=14.011199951171875, lr=8.881661974694362e-05
epochs:   8%|█████████████████████▌                                                                                                                                                                                                                                                                      | 76/1000 [1:47:35<21:28:55, 83.70s/it]2025-05-26 18:26:41,557   INFO  epoch: 76/1000, acc_iter=847, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:48:58/1:42:54, loss_hm=2.2654, loss_loc=7.3207, loss=12.580433585427024, d_time=0.03(0.06), f_time=0.47(0.65), b_time=0.50(0.71), norm=15.343879699707031, lr=8.981459138523513e-05
epochs:   8%|█████████████████████▊                                                                                                                                                                                                                                                                      | 77/1000 [1:49:00<21:33:11, 84.06s/it]2025-05-26 18:28:06,564   INFO  epoch: 77/1000, acc_iter=858, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:50:23/1:42:56, loss_hm=2.2031, loss_loc=7.2165, loss=12.395517869429154, d_time=0.03(0.05), f_time=0.46(0.71), b_time=0.49(0.76), norm=14.758529663085938, lr=9.082398613183116e-05
epochs:   8%|██████████████████████▏                                                                                                                                                                                                                                                                     | 78/1000 [1:50:25<21:35:40, 84.32s/it]2025-05-26 18:29:30,966   INFO  epoch: 78/1000, acc_iter=869, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:51:48/1:40:49, loss_hm=2.1772, loss_loc=7.1163, loss=12.345810023221103, d_time=0.04(0.06), f_time=0.44(0.65), b_time=0.48(0.71), norm=14.021869659423828, lr=9.184474172250909e-05
epochs:   8%|██████████████████████▍                                                                                                                                                                                                                                                                     | 79/1000 [1:51:50<21:35:04, 84.37s/it]2025-05-26 18:30:54,375   INFO  epoch: 79/1000, acc_iter=880, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:53:11/1:41:27, loss_hm=2.2124, loss_loc=7.1807, loss=12.42104348269376, d_time=0.03(0.06), f_time=0.46(0.74), b_time=0.48(0.79), norm=13.517613410949707, lr=9.287679519225578e-05
epochs:   8%|██████████████████████▋                                                                                                                                                                                                                                                                     | 80/1000 [1:53:13<21:29:51, 84.12s/it]2025-05-26 18:32:19,315   INFO  epoch: 80/1000, acc_iter=891, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:54:36/1:43:28, loss_hm=2.1585, loss_loc=7.2599, loss=12.48231384970925, d_time=0.03(0.05), f_time=0.46(0.64), b_time=0.49(0.69), norm=14.260868072509766, lr=9.3920082879152e-05
epochs:   8%|███████████████████████                                                                                                                                                                                                                                                                     | 81/1000 [1:54:38<21:31:12, 84.30s/it]2025-05-26 18:33:42,358   INFO  epoch: 81/1000, acc_iter=902, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:55:59/1:43:10, loss_hm=2.2082, loss_loc=7.1693, loss=12.433778242631393, d_time=0.04(0.06), f_time=0.47(0.67), b_time=0.51(0.73), norm=13.17991828918457, lr=9.497454042829874e-05
epochs:   8%|███████████████████████▎                                                                                                                                                                                                                                                                    | 82/1000 [1:56:01<21:24:05, 83.93s/it]2025-05-26 18:34:58,154   INFO  epoch: 82/1000, acc_iter=913, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:57:15/1:41:54, loss_hm=2.0584, loss_loc=7.1389, loss=12.323317007585006, d_time=0.04(0.05), f_time=0.46(0.60), b_time=0.49(0.65), norm=12.529317855834961, lr=9.604010279578754e-05
epochs:   8%|███████████████████████▌                                                                                                                                                                                                                                                                    | 83/1000 [1:57:17<20:45:28, 81.49s/it]2025-05-26 18:36:22,486   INFO  epoch: 83/1000, acc_iter=924, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 1:58:39/1:44:45, loss_hm=2.2114, loss_loc=7.2248, loss=12.467412428422408, d_time=0.03(0.06), f_time=0.46(0.72), b_time=0.50(0.78), norm=12.450298309326172, lr=9.711670425271226e-05
epochs:   8%|███████████████████████▊                                                                                                                                                                                                                                                                    | 84/1000 [1:58:41<20:57:13, 82.35s/it]2025-05-26 18:37:48,325   INFO  epoch: 84/1000, acc_iter=935, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:00:05/1:41:26, loss_hm=2.0826, loss_loc=7.2206, loss=12.455767544833096, d_time=0.03(0.05), f_time=0.46(0.66), b_time=0.49(0.71), norm=12.93841552734375, lr=9.820427838922374e-05
epochs:   8%|████████████████████████▏                                                                                                                                                                                                                                                                   | 85/1000 [2:00:07<21:11:38, 83.39s/it]2025-05-26 18:39:13,201   INFO  epoch: 85/1000, acc_iter=946, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 2:01:30/1:48:48, loss_hm=2.2127, loss_loc=7.1610, loss=12.384994940324264, d_time=0.04(0.05), f_time=0.45(0.64), b_time=0.49(0.69), norm=12.757171630859375, lr=9.930275811862642e-05
epochs:   9%|████████████████████████▍                                                                                                                                                                                                                                                                   | 86/1000 [2:01:32<21:17:01, 83.83s/it]2025-05-26 18:40:38,829   INFO  epoch: 86/1000, acc_iter=957, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 2:02:56/2:12:13, loss_hm=2.2142, loss_loc=7.3609, loss=12.560160810297186, d_time=0.03(0.06), f_time=0.46(0.76), b_time=0.50(0.82), norm=13.77034854888916, lr=0.00010041207568151631
epochs:   9%|████████████████████████▋                                                                                                                                                                                                                                                                   | 87/1000 [2:02:58<21:23:59, 84.38s/it]2025-05-26 18:42:02,575   INFO  epoch: 87/1000, acc_iter=968, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 2:04:19/1:48:55, loss_hm=2.1111, loss_loc=7.1383, loss=12.31610142100941, d_time=0.03(0.05), f_time=0.46(0.72), b_time=0.50(0.77), norm=15.03155517578125, lr=0.00010153216264996071
epochs:   9%|████████████████████████▉                                                                                                                                                                                                                                                                   | 88/1000 [2:04:21<21:19:31, 84.18s/it]2025-05-26 18:43:25,540   INFO  epoch: 88/1000, acc_iter=979, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:05:42/1:41:39, loss_hm=2.2994, loss_loc=7.1635, loss=12.46022926677357, d_time=0.03(0.06), f_time=0.46(0.69), b_time=0.50(0.75), norm=13.62890338897705, lr=0.00010266294993171922
epochs:   9%|█████████████████████████▎                                                                                                                                                                                                                                                                  | 89/1000 [2:05:44<21:13:04, 83.85s/it]2025-05-26 18:44:49,312   INFO  epoch: 89/1000, acc_iter=990, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:07:06/1:39:43, loss_hm=2.1897, loss_loc=7.2165, loss=12.422138907692649, d_time=0.03(0.05), f_time=0.44(0.66), b_time=0.47(0.72), norm=14.230032920837402, lr=0.00010380436777450604
epochs:   9%|█████████████████████████▌                                                                                                                                                                                                                                                                  | 90/1000 [2:07:08<21:10:50, 83.79s/it]2025-05-26 18:46:14,015   INFO  epoch: 90/1000, acc_iter=1000, cur_iter=9/11, batch_size=10, time_cost(epoch): 00:06/00:01, time_cost(all): 2:08:31/1:50:54, loss_hm=2.2097, loss_loc=7.2320, loss=12.494626331329346, d_time=0.03(0.06), f_time=0.83(0.68), b_time=0.86(0.74), norm=14.354721069335938, lr=0.0001048511859919157
2025-05-26 18:46:14,510   INFO  epoch: 90/1000, acc_iter=1001, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 2:08:31/1:48:19, loss_hm=2.4569, loss_loc=8.1840, loss=13.367303848266602, d_time=0.10(0.06), f_time=0.47(0.66), b_time=0.57(0.72), norm=14.05571174621582, lr=0.0001049563457702918600:00<?, ?it/s]
epochs:   9%|█████████████████████████▊                                                                                                                                                                                                                                                                  | 91/1000 [2:08:33<21:16:02, 84.23s/it]2025-05-26 18:47:39,794   INFO  epoch: 91/1000, acc_iter=1012, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:09:57/1:43:19, loss_hm=2.0702, loss_loc=7.1942, loss=12.4042799689553, d_time=0.03(0.06), f_time=0.47(0.63), b_time=0.50(0.69), norm=12.992193222045898, lr=0.0001061188128596478
epochs:   9%|██████████████████████████▏                                                                                                                                                                                                                                                                 | 92/1000 [2:09:58<21:19:16, 84.53s/it]2025-05-26 18:49:03,089   INFO  epoch: 92/1000, acc_iter=1023, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:11:20/1:43:13, loss_hm=2.0894, loss_loc=7.2249, loss=12.412157838994807, d_time=0.04(0.06), f_time=0.45(0.69), b_time=0.49(0.75), norm=13.86557388305664, lr=0.00010729169733612789
epochs:   9%|██████████████████████████▍                                                                                                                                                                                                                                                                 | 93/1000 [2:11:22<21:12:23, 84.17s/it]2025-05-26 18:50:27,669   INFO  epoch: 93/1000, acc_iter=1034, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:12:45/1:39:58, loss_hm=2.0921, loss_loc=7.2171, loss=12.480248017744584, d_time=0.03(0.05), f_time=0.44(0.64), b_time=0.47(0.69), norm=12.521750450134277, lr=0.00010847492685069299
epochs:   9%|██████████████████████████▋                                                                                                                                                                                                                                                                 | 94/1000 [2:12:46<21:13:00, 84.31s/it]2025-05-26 18:51:52,740   INFO  epoch: 94/1000, acc_iter=1045, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:14:10/1:45:12, loss_hm=2.2438, loss_loc=7.2316, loss=12.428942160172896, d_time=0.04(0.06), f_time=0.45(0.65), b_time=0.48(0.71), norm=13.14456558227539, lr=0.00010966842841617308
epochs:  10%|██████████████████████████▉                                                                                                                                                                                                                                                                 | 95/1000 [2:14:11<21:14:43, 84.51s/it]2025-05-26 18:53:17,169   INFO  epoch: 95/1000, acc_iter=1056, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:15:34/1:40:16, loss_hm=2.2243, loss_loc=7.1357, loss=12.354549061168324, d_time=0.03(0.05), f_time=0.46(0.65), b_time=0.49(0.71), norm=13.073263168334961, lr=0.00011087212841176964
epochs:  10%|███████████████████████████▎                                                                                                                                                                                                                                                                | 96/1000 [2:15:36<21:13:12, 84.51s/it]2025-05-26 18:54:42,427   INFO  epoch: 96/1000, acc_iter=1067, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:16:59/1:42:22, loss_hm=2.1344, loss_loc=7.1961, loss=12.39483287117698, d_time=0.03(0.06), f_time=0.46(0.63), b_time=0.50(0.69), norm=12.38786506652832, lr=0.00011208595258759707
epochs:  10%|███████████████████████████▌                                                                                                                                                                                                                                                                | 97/1000 [2:17:01<21:14:59, 84.72s/it]2025-05-26 18:56:07,479   INFO  epoch: 97/1000, acc_iter=1078, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:18:24/1:41:36, loss_hm=2.1897, loss_loc=7.1484, loss=12.387977860190652, d_time=0.03(0.06), f_time=0.46(0.70), b_time=0.49(0.76), norm=13.399138450622559, lr=0.0001133098260692626
epochs:  10%|███████████████████████████▊                                                                                                                                                                                                                                                                | 98/1000 [2:18:26<21:14:52, 84.80s/it]2025-05-26 18:57:32,330   INFO  epoch: 98/1000, acc_iter=1089, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:19:49/1:44:37, loss_hm=2.4421, loss_loc=7.1956, loss=12.41218306801536, d_time=0.04(0.06), f_time=0.46(0.64), b_time=0.50(0.70), norm=13.452800750732422, lr=0.00011454367336248485
epochs:  10%|████████████████████████████                                                                                                                                                                                                                                                                | 99/1000 [2:19:51<21:13:48, 84.83s/it]2025-05-26 18:58:57,226   INFO  epoch: 99/1000, acc_iter=1100, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:06/00:00, time_cost(all): 2:21:14/1:41:29, loss_hm=2.1511, loss_loc=7.1912, loss=12.407542835582387, d_time=0.04(0.06), f_time=0.45(0.68), b_time=0.49(0.73), norm=15.38562297821045, lr=0.00011578741835775101
epochs:  10%|████████████████████████████▎                                                                                                                                                                                                                                                              | 100/1000 [2:21:16<21:14:11, 84.95s/it]2025-05-26 19:00:23,402   INFO  epoch: 100/1000, acc_iter=1111, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:07/00:00, time_cost(all): 2:22:40/1:50:03, loss_hm=2.2305, loss_loc=7.1092, loss=12.332154273986816, d_time=0.03(0.06), f_time=0.46(0.69), b_time=0.49(0.74), norm=14.40429401397705, lr=0.00011704098433501097
epochs:  10%|████████████████████████████▌                                                                                                                                                                                                                                                              | 101/1000 [2:22:42<21:16:51, 85.22s/it]2025-05-26 19:01:47,676   INFO  epoch: 101/1000, acc_iter=1122, cur_iter=10/11, batch_size=8, time_cost(epoch): 00:08/00:00, time_cost(all): 2:24:05/2:03:39, loss_hm=2.1740, loss_loc=7.2958, loss=12.444726597179066, d_time=0.04(0.06), f_time=0.46(0.67), b_time=0.50(0.72), norm=12.89254093170166, lr=0.00011830429396841055
epochs:  10%|████████████████████████████▊                                                                                                                                                                                                                                                              | 102/1000 [2:25:22<21:19:51, 85.51s/it]
Traceback (most recent call last):                                                                                                                                                                                                                                                                                       | 0/11 [00:00<?, ?it/s]
  File "/home/shchoi/workspace/DSVT/tools/train.py", line 211, in <module>
    main()
  File "/home/shchoi/workspace/DSVT/tools/train.py", line 158, in main
    train_model(
  File "/home/shchoi/workspace/DSVT/tools/train_utils/train_utils.py", line 224, in train_model
    accumulated_iter = train_one_epoch(
  File "/home/shchoi/workspace/DSVT/tools/train_utils/train_utils.py", line 75, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/__init__.py", line 42, in model_func
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
    return inner()
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
    result = forward_call(*args, **kwargs)
  File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/detectors/centerpoint.py", line 11, in forward
    batch_dict = cur_module(batch_dict)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/backbones_2d/base_bev_res_backbone.py", line 132, in forward
    x = self.blocks[i](x)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/backbones_2d/base_bev_res_backbone.py", line 38, in forward
    out = self.bn1(out)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 810, in forward
    return sync_batch_norm.apply(
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/_functions.py", line 102, in forward
    counts = count_all.view(-1)
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/train.py", line 211, in <module>
[rank0]:     main()
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/train.py", line 158, in main
[rank0]:     train_model(
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/train_utils/train_utils.py", line 224, in train_model
[rank0]:     accumulated_iter = train_one_epoch(
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/train_utils/train_utils.py", line 75, in train_one_epoch
[rank0]:     loss, tb_dict, disp_dict = model_func(model, batch)
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/__init__.py", line 42, in model_func
[rank0]:     ret_dict, tb_dict, disp_dict = model(batch_dict)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank0]:     return inner()
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/detectors/centerpoint.py", line 11, in forward
[rank0]:     batch_dict = cur_module(batch_dict)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/backbones_2d/base_bev_res_backbone.py", line 132, in forward
[rank0]:     x = self.blocks[i](x)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
[rank0]:     input = module(input)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/shchoi/workspace/DSVT/tools/../pcdet/models/backbones_2d/base_bev_res_backbone.py", line 38, in forward
[rank0]:     out = self.bn1(out)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 810, in forward
[rank0]:     return sync_batch_norm.apply(
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:   File "/home/shchoi/anaconda3/envs/open3d_data/lib/python3.10/site-packages/torch/nn/modules/_functions.py", line 102, in forward
[rank0]:     counts = count_all.view(-1)
[rank0]: KeyboardInterrupt
